import os
import sys
import threading
import pyaudio
from vosk import Model, KaldiRecognizer

from PyQt5.QtGui import QIcon
from PyQt5.QtCore import Qt, QSize

from PyQt5.QtWidgets import (
    QApplication, QWidget, QVBoxLayout, QPushButton,
    QTextEdit, QLabel, QHBoxLayout, QSizePolicy
)


class VoiceRecognizer(QWidget):
    def __init__(self):
        super().__init__()

        self.setWindowTitle("VOSK ìŒì„± ì¸ì‹ê¸°")
        self.setFixedSize(400, 400)  # ì°½ í¬ê¸° ê³ ì •

        self.init_ui()

        # ìŒì„± ì¸ì‹ ê´€ë ¨ ë³€ìˆ˜
        self.model_path = "models/vosk-model-en-us-0.42-gigaspeech"
        self.sample_rate = 8000
        self.chunk_size = 1024
        self.running = False

        if not os.path.exists(self.model_path):
            self.label.setText("âŒ ëª¨ë¸ ê²½ë¡œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            self.mic_button.setEnabled(False)
        else:
            self.model = Model(self.model_path)
            self.rec = KaldiRecognizer(self.model, self.sample_rate)

    def init_ui(self):
        layout = QVBoxLayout()
        layout.setAlignment(Qt.AlignCenter)

        self.label = QLabel("ğŸ¤ ì•„ë˜ ë²„íŠ¼ì„ ëˆŒëŸ¬ ìŒì„± ì¸ì‹ì„ ì‹œì‘í•˜ì„¸ìš”.")
        self.label.setAlignment(Qt.AlignCenter)
        layout.addWidget(self.label)

        self.text_edit = QTextEdit()
        self.text_edit.setReadOnly(True)
        layout.addWidget(self.text_edit)

        # ë§ˆì´í¬ ë²„íŠ¼ (ì¤‘ì•™ ë°°ì¹˜)
        self.mic_button = QPushButton()
        self.mic_button.setIcon(QIcon.fromTheme("microphone"))
        self.mic_button.setText("ë§ˆì´í¬")
        self.mic_button.setIconSize(QSize(24, 24))
        self.mic_button.setFixedHeight(40)
        self.mic_button.clicked.connect(self.toggle_recognition)
        self.mic_button.setStyleSheet("""
            QPushButton {
                background-color: #2196F3;
                color: white;
                border: none;
                border-radius: 20px;
                font-weight: bold;
                padding: 8px 16px;
            }
            QPushButton:hover {
                background-color: #1976D2;
            }
        """)
        layout.addWidget(self.mic_button, alignment=Qt.AlignCenter)

        self.setLayout(layout)

    def toggle_recognition(self):
        if not self.running:
            self.start_recognition()
        else:
            self.stop_recognition()

    def start_recognition(self):
        self.running = True
        self.mic_button.setText(" ğŸ”‡ ì¤‘ì§€")
        self.label.setText("ğŸŸ¢ ìŒì„± ì¸ì‹ ì¤‘... ë§ˆì´í¬ì— ë§í•˜ì„¸ìš”.")
        self.text_edit.clear()

        self.thread = threading.Thread(target=self.recognize)
        self.thread.start()

    def stop_recognition(self):
        self.running = False
        self.mic_button.setText(" ìŒì„± ì¸ì‹ ì‹œì‘")
        self.label.setText("â¹ï¸ ìŒì„± ì¸ì‹ì´ ì¤‘ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.")

    def recognize(self):
        p = pyaudio.PyAudio()
        stream = p.open(format=pyaudio.paInt16,
                        channels=1,
                        rate=self.sample_rate,
                        input=True,
                        frames_per_buffer=self.chunk_size)

        stream.start_stream()

        try:
            while self.running:
                data = stream.read(self.chunk_size, exception_on_overflow=False)
                if self.rec.AcceptWaveform(data):
                    result = self.rec.Result()
                    text = eval(result)["text"]
                    if text.strip():
                        self.text_edit.append(f"{text}")
        except Exception as e:
            self.text_edit.append(f"â— ì˜¤ë¥˜ ë°œìƒ: {e}")
        finally:
            stream.stop_stream()
            stream.close()
            p.terminate()


if __name__ == "__main__":
    app = QApplication(sys.argv)
    window = VoiceRecognizer()
    window.show()
    sys.exit(app.exec_())
